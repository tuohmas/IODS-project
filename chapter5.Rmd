# Exercise 5, Week 5: Dimensionality reduction techniques

Dimensionality reduction techniques exercise is performed on previously merged "human" data set, read from GitHub repo. It consist of combined Human Development and Gender inequality data sets on country level. Description of original data can be found [here](http://hdr.undp.org/en/content/human-development-index-hdi) and [here](http://hdr.undp.org/sites/default/files/hdr2015_technical_notes.pdf), respectively.

```{r}
# Read human.csv
human <- read.table("https://raw.githubusercontent.com/tuohmas/IODS-project/master/data/human.csv", 
                    header = T, sep = ";")
str(human)
summary(human)

# Access GGally
library(tidyverse)
library(GGally)

# visualize the 'human_' variables
GGally::ggpairs(human)

# compute the correlation matrix and visualize it with corrplot
cor(human) %>% corrplot::corrplot()

```
Out of statistically significant relationships between variables, there is a stong negative correlation between **maternal mortality ratio (mat_mortality)** and **life expectancy at birth (life_exp_birth)** ( _r_ = -0.857, _p_ < 0.001). In addition, there exists a moderately strong relationship between **life expectancy at birth (life_exp_birth)** and **expected Years of Education (edu_expected)** ( _r_ = 0.789, _p_ < 0.001), **(adol_birth_rate)** and **maternal mortality ratio (mat_mortality)** ( _r_ = 0.759, _p_ < 0.001), as well as **maternal mortality ratio (mat_mortality)** and **Expected Years of Education (edu_expected)** ( _r_ = ,_p_ < 0.001).

## Principal Component Analysis

```{r}

# perform principal component analysis (with the SVD method)
pca_human <- prcomp(human)
summary(pca_human)

# draw a biplot of the principal component representation and the original variables
biplot(pca_human, choices = 1:2, cex = c(0.5, 0,5),col = c("grey30", "deeppink2"))

# Exploring the variances of human variables
library(psych)
describe(human)
rev(sort(summarise_if(human, is.numeric, var)))

```
According to the summary, The first principal component is capturing unusually high proportion of the total variance in unstandardized human data, more than 99,99 per cent. This very skewed result is reflected also in the biplot:

* Observations are heavily concentrated to the top right corner, which represents...
* The arrows show that **gross national income (GNI per capita)** is having an undue influence to the model, 

How accurate is this pictur? We know that Pricipal Component Analysis is sensitive to the relative sclaing of original features, and is easily tipped off by variables that have larger variance compared to ones with smaller variance. We might deduce that GNI per capita dominates other, and indeed, its variance (343874462) is many orders of magnitudes higher than the next one, maternal mortality (44854.83).

Let's therefore standardize (scale) our human data before performing any PCA.

```{r}

# standardize the variables
human_std <- scale(human)

# print out summaries of the standardized variables
summary(human_std)

# perform principal component analysis (with the SVD method)
pca_human <- prcomp(human_std)

# create and print out a summary of pca_human
summary <- summary(pca_human)
summary

# rounded percetanges of variance captured by each PC
pca_pr <- round(100*summary$importance[2, ], digits = 2)

# create object pc_lab to be used as axis labels
pc_lab <- paste0(names(pca_pr), " (", pca_pr, "%)")

# draw a biplot of the principal component representation and the original variables
biplot(pca_human, choices = 1:2, cex = c(0.5, 0.9),col = c("grey30", "deeppink2"), xlab = pc_lab[1], ylab = pc_lab[2], main = "Prinicipal Component Analysis")

```
For standardized human data, first PC captures much more believable proportion of total variance in data, about 54%, and together with PC2, about 70%. Including more than two PCs would benefit us only marginally as the total variance grows by less than ten per cent with each new dimensions we introduce.  

Biplotting the first two principal components tells us that:

* PC1 is contributed by six variables (small angel between these features and PC1 axis): **(edu_expected)**, **(life_exp_birth)**, **(gni_per_capita)**, and **(edu2_f2m)**, that are highly positively correlated together, and **(mat_mortality)**, **(adol_birth_rate)**, that are highly and positively correlated to one another, and negatively correlated to the former four. 
* PC2 is contributed by **female shares of parliamentary seats (repr)** and **female vs male labour force participation rate ratio (lab_f2m)**, that are minimally to other six variables (arrows at almost righ angles) 
* Most of the variables have similarly large standard devations (arrow length)

There is no clear cut way to interpret our two PCs. However, it seems that [UN designated dimensions](http://hdr.undp.org/sites/default/files/hdr2015_technical_notes.pdf)"A decent standard of living", "Health" and "Education" are better represented on PC1, whereas PC2 is primarily composed on indicators that measure "Empowerment" and "Labour market".

## Multiple Correspondence Analysis

For Multiple Correspondence Analysis we will explore tea data set. For futher meta data, see  ?tea.

```{r}

# column names to keep in the dataset
library(FactoMineR)

# load data set "tea"
data("tea")
glimpse(tea)

keep_columns <- c("Tea", "How", "how", "sugar", "where", "lunch")

# select the 'keep_columns' to create a new dataset
tea_time <- dplyr::select(tea, one_of(keep_columns))

# look at the summaries and structure of the data
summary(tea_time)
str(tea_time)

# visualize the dataset
gather(tea_time) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar() + theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8))

```

```{r}
mca <- MCA(tea_time, graph = FALSE)

# summary of the model
summary(mca)

# visualize MCA
plot(mca, invisible=c("ind"), habillage = "quali", graph.type = "classic")

```
Data is visualised on first two dimensions that capture 29.4% of its total variance.
 
From the summary we see that:

* Cumulative percentage of variances retained by each dimension does not reach 50% before including full four dimensions.
* **How**, **how** and **where** have strong link between Dimension 1; **where** and **how** have somewhat strong link with Dimension 2; and no variables have particularily strong link with Dimension 3 (Categorical variable is closest to one).

From the biplot we see that:

* A cluster of names and lables, including **chain store**, **tea bag**; **Not.lunch**, **alone**; and **milk**, **sugar**, and **Earl Gray** are clumped to the centre, and similir with one another (close distances)
* **green** and **other** are not similar to any other label or name (great distances)